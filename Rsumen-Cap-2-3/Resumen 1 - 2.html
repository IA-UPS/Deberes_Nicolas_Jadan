<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Resumen Cap 1/2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Resumen 1 - 2_files/libs/clipboard/clipboard.min.js"></script>
<script src="Resumen 1 - 2_files/libs/quarto-html/quarto.js"></script>
<script src="Resumen 1 - 2_files/libs/quarto-html/popper.min.js"></script>
<script src="Resumen 1 - 2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Resumen 1 - 2_files/libs/quarto-html/anchor.min.js"></script>
<link href="Resumen 1 - 2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Resumen 1 - 2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Resumen 1 - 2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Resumen 1 - 2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Resumen 1 - 2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Resumen Cap 1/2</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="resumen-capítulos-2-3" class="level1">
<h1>Resumen Capítulos 2-3</h1>
<p><strong>Integrantes:</strong> María José Bustamante - Nicolás Jadán</p>
<p><strong>Carrera:</strong> Biomedicina</p>
</section>
<section id="capítulo-2" class="level1">
<h1>CAPÍTULO 2</h1>
</section>
<section id="aprendizaje-estadístico" class="level1">
<h1>Aprendizaje estadístico</h1>
<section id="qué-es-el-aprendizaje-estadístico" class="level2">
<h2 class="anchored" data-anchor-id="qué-es-el-aprendizaje-estadístico">¿Qué es el aprendizaje estadístico?</h2>
<p>Ayuda a determinar si existe una relación entre las variables de interés para su futura aplicación.</p>
<p>Variable de entrada (input): Suelen denotarse como “X” y con un subídice para diferenciarlas. Se conocen como; predictores, características y variables independientes.</p>
<p>Variable de salida (output): Se denota como “Y”. Conocida generalmente como variable dependiente o de respuesta.</p>
<p>El aprendizaje estadístico se refiere a un conjunto de enfoques para estimar <em>f</em> que es una función fija pero desconocida que representa información sistemática que brinda X acerca de Y.</p>
<section id="cómo-estimar-f" class="level3">
<h3 class="anchored" data-anchor-id="cómo-estimar-f">¿Cómo estimar <em>f</em>?</h3>
<p><strong>Predicción</strong></p>
<p>Generalmente se suele tener los datos de entrada pero la parte difícil es obtener la salida. Esto se puede solucionar usando:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/predicci%C3%B3n.png" width="82" height="34" class="figure-img"></p>
</figure>
</div>
<p>f: estimación para f</p>
<p>y: predicción resultante</p>
<p>Un ejemplo se muestra en la siguiente imagen:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/imagen%20prediccion.png" class="img-fluid figure-img" width="283"></p>
</figure>
</div>
<p>El gráfico muestra los ingresos en función de los años de educación y antigüedad en el conjunto de datos Renta. La superficie azul representa la verdadera relación subyacente entre los ingresos y los años de educación y antigüedad, que se conoce porque los datos son simulados. Los puntos rojos indican los valores de estas cantidades para 30 individuos.</p>
<p>La exactitud de y depende de dos tipos de error:</p>
<ul>
<li><p>Error reducible: Se refiere a la precisión de las predicciones que puede mejorar implementando mejores algoritmos para estimar f(X).</p></li>
<li><p>Error irreducible: Aunque fuera posible obtener la mejor estimación de f(X), seguirá existiendo un cierto nivel de incertidumbre ya que siempre existen dependencias de la variable objetivo con otras variables que no se están considerando o simplemente por procesos debidos al azar. Esto es lo que se conoce como error irreducible. Siempre proporcionará un límite superior en la precisión de la predicción para Y.</p></li>
</ul>
<p><strong>Inferencia</strong></p>
<p>Para comprender la asociación entre Y y Xp se pueden plantear las siguientes preguntas:</p>
<ol type="1">
<li><p><em>¿Qué predictores se asocian a la respuesta?</em></p></li>
<li><p><em>¿Cuál es la relación entre la respuesta y cada predictor?</em></p></li>
<li><p><em>¿Puede resumirse adecuadamente la relación entre Y y cada predictor mediante una ecuación lineal, o la relación es más complicada?</em></p></li>
</ol>
<p>Algunos modelos podrían utilizarse tanto para la predicción como para la inferencia, dependiendo delobjetivo final. Por ejemplo, los modelos lineales permiten una inferencia relativamente sencilla y predecible entre modelos lineales, pero puede que no produzcan predicciones tan precisas como otros enfoques. Por el contrario, algunos de los enfoques no lineales pueden brindar información bastante precisas para Y.</p>
</section>
</section>
<section id="cómo-estimamos-f" class="level2">
<h2 class="anchored" data-anchor-id="cómo-estimamos-f">¿Cómo estimamos f?</h2>
<p><strong>Métodos paramétricos</strong>: Abarcan un enfoque basado en modelos de dos pasos:</p>
<ol type="1">
<li><p>Suposición sobre la forma funcional para el modelo. Ej: f es lineal en X.</p></li>
<li><p>Después de seleccionar el modelo se requiere de un procedimiento que utilice los datos de entrenamiento para ajustar o entrenar el modelo.</p></li>
</ol>
<p>El método más común para ajustar un modelo es el de mínimos cuadrados.</p>
<p>Ejemplo:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/lineal%20mod.png" class="img-fluid figure-img" width="377"></p>
<p></p><figcaption class="figure-caption"><em>Modelo lineal ajustado por mínimos cuadrados a datos de ingresos. Las observaciones se muestran en rojo, y el plano amarillo indica el ajuste por mínimos cuadrados a los datos.</em></figcaption><p></p>
</figure>
</div>
<p>El modelo paramétrico reduce el problema para estimar f ya que se presenta como un conjunto de parámetros en el modelo lineal caso contario se debería ajustar f a una función arbitraria.</p>
<p>La desventaja de este modelo es que cuando el modelo elegido se aleje demasiado la estimación será deficiente y para resolver esto se debería estimar una mayor cantidad de parámetros lo que a su vez podría provocar un sobreaajuste de datos.</p>
<p><strong>Métodos no paramétricos:</strong> Buscan una estimación de f que se acerque lo más posible a los puntos de datos sin que sea demasiado aproximada. Se ajustan fácilmente a una gama más amplia de formas posibles de f.</p>
<p>Una desventaja que presentan es que se necesita un gran número de observaciones para obtener una estimación precisa de f.</p>
</section>
<section id="el-equilibrio-entre-la-precisión-de-la-predicción-y-la-interpretabilidad-del-modelo" class="level2">
<h2 class="anchored" data-anchor-id="el-equilibrio-entre-la-precisión-de-la-predicción-y-la-interpretabilidad-del-modelo">El equilibrio entre la precisión de la predicción y la interpretabilidad del modelo</h2>
<p>Existen métodos menos flexible o menos restrictivos en el sentido de que sólo pueden producir una gama relativamente pequeña de formas para estimar f.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/flexibilidad.png" class="img-fluid figure-img" width="467"></p>
<p></p><figcaption class="figure-caption"><em>Representación de la relación entre flexibilidad e interpretabilidad, utilizando diferentes métodos de aprendizaje estadístico. En general, a medida que aumenta la flexibilidad de un método, disminuye su interpretabilidad.</em></figcaption><p></p>
</figure>
</div>
<p><em>Modelo restrictivo:</em> Es útil cuando el principal interés es la inferencia, debido a que es más interpretable.</p>
<p><em>Modelos flexibles:</em> Pueden guiar a estimaciones muy complicadas de f en las que es difícil comprender cómo se asocia cualquier predictor con la respuesta.</p>
<ul>
<li><p>lasso: es un enfoque menos flexible y más interpretable que la regresión lineal proque en el modelo final la respuesta sólo estará relacionada con el modelo final.</p></li>
<li><p>Modelos aditivos generalizados (GAM): Más felxibles que la regresión lineal, pero menos interpretables ya que la relación entre cada predictor y respuesta se representa mediante una curva.</p></li>
<li><p>Modelos no lineales: bagging, boosting, máquinas de soporte de vectores y redes neuronales.</p></li>
</ul>
</section>
<section id="aprendizaje-supervisado-frente-a-aprendizaje-no-supervisado" class="level2">
<h2 class="anchored" data-anchor-id="aprendizaje-supervisado-frente-a-aprendizaje-no-supervisado">Aprendizaje supervisado frente a aprendizaje no supervisado</h2>
<p>Supervisado: Para cada observación de los predictores hay una respesta asociada. Permite predecir con exactitud la prespuesta para futuras predicciones o comprender mejor la relaxción entre predictores y respuesta.</p>
<p>No supervisado: Se carece de una variable de respuesta que pueda supervisar el análisis. Es decir no hay una respuesta asociada al predictor, por lo que no e sposible ajustar a un modelo de regresión lineal.</p>
</section>
<section id="problemas-de-regresión-frente-a-problemas-de-clasificación" class="level2">
<h2 class="anchored" data-anchor-id="problemas-de-regresión-frente-a-problemas-de-clasificación">Problemas de regresión frente a problemas de clasificación</h2>
<p>Variables cuantitativas: Toman valores numéricos. Ej: Estatura, edad o ingresos.</p>
<p>Variables cualitativas: Toman valores en clases o categorías. Ej: Estado cívil, marcas de productos o diagnósticos.</p>
<p>La regresión logística es un método de clasificación binaria. Es bastante común seleccionar los métodos de aprendizaje estadístico en función de si la respuesta es cuantitativa o cualitativa, es decir, se puede usar la regresión lineal cuando es cuantitativa y la regresión logística cuando es cualitativa.</p>
</section>
</section>
<section id="evaluación-de-la-precisión-de-los-modelos" class="level1">
<h1>Evaluación de la precisión de los modelos</h1>
<p>En en estadística: ningún método domina a todos los demás en todos los conjuntos de datos posibles.</p>
<section id="medir-la-calidad-del-ajuste" class="level2">
<h2 class="anchored" data-anchor-id="medir-la-calidad-del-ajuste">Medir la calidad del ajuste</h2>
<p>Para evaluar el rendimiento de un método de aprendizaje estadístico se requiere cuantificar hasta qué punto el valor de respuesta predicho para una observación dada se aproxima al valor de respuesta verdadero para esa observación.</p>
<p><em>Error cuadrático medio (MSE):</em> será pequeño si las respuestas predichas están muy cerca de las respuestas verdaderas, y será grande si para algunas de las observaciones, las respuestas predichas y verdaderas difieren sustancialmente.</p>
<p>Se calcula utilizando los datos de entrenamiento que se usaron para jaustar el modelo</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/MSE.png" class="img-fluid figure-img" width="481"></p>
<p></p><figcaption class="figure-caption"><em><strong>Izquierda:</strong> Datos simulados a partir de f, mostrados en negro. Se muestran tres estimaciones de f: la línea de regresión lineal (curva naranja) y dos splines de suavizado (curvas azul y verde). (curvas azul y verde). <strong>Derecha:</strong> MSE de entrenamiento (curva gris), MSE de prueba (curva roja roja) y el MSE de prueba mínimo posible de todos los métodos (línea discontinua). Los cuadrados MSE de entrenamiento y prueba de los tres ajustes mostrados en el panel izquierdo.</em></figcaption><p></p>
</figure>
</div>
<p>En la imagen en la parte izquierda se puede ver que a medida que aumenta el nivel de flexibilidad, las curvas se ajustan mejor a los datos observados. La curva verde es la más flexible y se ajusta muy bien a los datos; sin embargo, observamos que se ajusta mal a la f verdadera (mostrada en negro) porque es demasiado ondulada.</p>
<p>En la parte derecha La curva gris muestra el MSE medio de entrenamiento en función de la flexibilidad, o más formalmente de los grados de libertad (flexibilidad de la curva). Los cuadrados naranja, azul y verde indican los MSE asociados a las curvas.</p>
<p>En este ejemplo, la verdadera f no es lineal, por lo que el ajuste lineal naranja no es lo suficientemente flexible para estimar bien f.&nbsp;La curva verde tiene el MSE de entrenamiento más bajo de los tres métodos, ya que corresponde al más flexible de ellos. El spline de suavizado representado por la curva azul se aproxima al óptimo.</p>
<p>En la parte derecha de la figura, a medida que aumenta la flexibilidad del método de aprendizaje estadístico, observamos un descenso monótono en el tiempo de entrenamiento. Es decir, a medida que aumenta la flexibilidad del modelo aumenta, el MSE de entrenamiento disminuirá.</p>
<p>Cuando un método determinado produce un MSE de entrenamiento pequeño pero un MSE de prueba grande, se dice que se están sobreajustando los datos.</p>
</section>
<section id="la-relación-entre-sesgo-y-varianza" class="level2">
<h2 class="anchored" data-anchor-id="la-relación-entre-sesgo-y-varianza">La relación entre sesgo y varianza</h2>
<p>Para minimizar el error de prueba esperado se requiere seleccionar un método de aprendizaje estadístico que consiga simultáneamente baja varianza y bajo sesgo.</p>
<p>Varianza: Se refire a la cantidad en la que <em>f</em> cambiaría si la estimación se realizara usando un conjunto de datos de enttrenamiento diferente. Lo ideal es que la estimación de f no varíe demasiado. En general los métodos estadísticos más flexibles tienen mayor varianza.</p>
<p>Sesgo: Es el error que se introduce al aproximar un problema de la vida real a un modelo muy simple o sencillo. Es poco probable que un problema de la vida real tenga una relación lineal tan sencilla, por lo que realizar una regresión lineal dará lugar a cierto sesgo en la estimación de f.</p>
<p>La varianza es intrínsecamente una cantidad no negativa, y el sesgo al cuadrado también es no negativo.</p>
<p>A medida que utilicemos métodos más flexibles, la varianza aumentará y el sesgo disminuirá.</p>
<p>Un buen rendimiento del conjunto de prueba de un método de aprendizaje estadístico requiere una varianza baja, así como un equilibrio entre sesgo y varianza.</p>
</section>
<section id="el-entorno-de-clasificación" class="level2">
<h2 class="anchored" data-anchor-id="el-entorno-de-clasificación">El entorno de clasificación</h2>
<p>Las tasas de error resultantes son de especial interés para la aplicación del clasificador a observaciones de prueba que no fueron utilizadas en el entrenamiento. Un buen clasificador es aquel en el que el error de prueba es mínimo.</p>
<section id="el-clasificador-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="el-clasificador-de-bayes">El clasificador de Bayes</h3>
<p>Asigna cada observación a la clase más probable dados sus valores predictores. En un problema de dos clases en el que sólo hay dos posibles valores de respuesta, el clasificador de Bayes corresponde a la predicción de la clase uno si Pr(Y = 1|X = x0) &gt; 0,5, y la clase dos en caso contrario.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/bayes.png" class="img-fluid figure-img" width="411"></p>
<p></p><figcaption class="figure-caption"><em>Un conjunto de datos simulados compuesto por 100 observaciones en cada uno de dos grupos, indicados en azul y en naranja. La línea discontinua morada representa el límite de decisión de Bayes. La cuadrícula de fondo naranja indica la región en la que una observación de prueba se asignará a la clase naranja, y la cuadrícula de fondo azul azul indica la región en la que una observación de prueba se asignará a la clase azul. a la clase azul.</em></figcaption><p></p>
</figure>
</div>
<p>En la imagen los círculos naranja y azules corresponden a observaciones de entrenamiento que pertenecen a dos clases diferentes.</p>
<p>Para cada valor de X1 y X2, existe una probabilidad diferente de que la respuesta sea naranja o azul.</p>
<p>La región sombreada en naranja refleja el conjunto de puntos para los que Pr(Y = naranja|X) es superior al 50 %, mientras que la región sombreada en azul indica el conjunto de puntos cuya probabilidad es inferior al 50 %.</p>
<p>La línea discontinua morada representa los puntos en los que la probabilidad es exactamente del 50 %. Esto se denomina el <strong>límite de decisión de Bayes.</strong></p>
</section>
<section id="k-nearest-neighbors" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors">K-Nearest Neighbors</h3>
<p>Es utilizado para trabajar con datos reales. Es un algoritmo no supervisado donde “K” representa el número de “grupos” (clusters) a clasificar y el K-neighbor más cercano “K” representa el número de “vecinos” considerados en los “n” grupos del clasificador. En otras palabras busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/k-neig.png" class="img-fluid figure-img" width="446"></p>
<p></p><figcaption class="figure-caption"><em>Comparación de los límites de decisión KNN (curvas negras obtenidas utilizando K = 1 y K = 100 en los datos de la Figura 2.13. Con K = 1, el límite de decisión es demasiado flexible, mientras que con K = 100 no es suficientemente flexible. El límite de decisión de Bayes se muestra como una línea discontinua morada.</em></figcaption><p></p>
</figure>
</div>
<p>La imagen muestra dos ajustes KNN a los datos simulados, utilizando K = 1 y K = 100. Cuando K = 1, el límite de decisión es excesivamente flexible y encuentra patrones en los datos que no se corresponden con el límite de decisión de Bayes. Esto corresponde a un clasificador que tiene un sesgo bajo pero una varianza muy alta. A medida que K aumenta, el método se vuelve menos flexible y produce una frontera de decisión cercana a la lineal. Esto corresponde a un clasificador de baja varianza pero alto sesgo. En este conjunto de datos simulados, ni K = 1 ni K = 100 dan buenas predicciones: tienen tasas de error de prueba de 0,1695 y 0,1925, respectivamente.</p>
</section>
</section>
</section>
<section id="lab-cap-3---regresión-linear" class="level1">
<h1>LAB: CAP 3 - Regresión linear</h1>
<p>Librerías a usar:</p>
<p>MASS: colección de conjunto de datos y funciones.</p>
<p>ISLR2: Conjunto de datos asociados al libro de estudio.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (MASS)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (ISLR2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'ISLR2'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:MASS':

    Boston</code></pre>
</div>
</div>
<section id="regresión-linear-simple" class="level2">
<h2 class="anchored" data-anchor-id="regresión-linear-simple">Regresión linear simple</h2>
<p>La biblioteca ISLR2 contiene el conjunto de datos de Boston, que registra el medv (valor medio de la vivienda) de 506 secciones censales de Boston. Intentaremos predecir medv utilizando 12 predictores como rm (número medio de habitaciones por casa) edad (edad media de las casas) y lstat (porcentaje de hogares con un estatus socioeconómico bajo).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Boston)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     crim zn indus chas   nox    rm  age    dis rad tax ptratio lstat medv
1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3  4.98 24.0
2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8  9.14 21.6
3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8  4.03 34.7
4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7  2.94 33.4
5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7  5.33 36.2
6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7  5.21 28.7</code></pre>
</div>
</div>
<ul>
<li><p><strong>?Boston:</strong> Para obtener información sobre el conjunto de datos.</p></li>
<li><p><strong>lm():</strong> Para ajustar un modelo de regresión lineal simple.</p></li>
<li><p><strong>Predictor:</strong> Istat</p></li>
<li><p><strong>Respuesta:</strong> medv</p></li>
</ul>
<p>La sintaxis básica es lm(y ∼ x, datos), donde y es la respuesta, x es el predictor y datos es el conjunto de datos en el que se mantienen estas dos variables.</p>
<p>Si escribimos lm.fit, aparecerá información básica sobre el modelo.</p>
<p>Para obtener información más detallada, utilice summary(lm.fit). Se obtienen los valores p y los errores estándar de los coeficientes, así como el estadístico R2</p>
<p>y el estadístico F del modelo.</p>
<p>Podemos utilizar la función names() para averiguar qué otras piezas names() de información se almacenan en lm.fit.</p>
<p>Es más seguro utilizar las funciones extractoras como coef() para acceder a ellas.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>